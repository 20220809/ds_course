{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YOCAyTf_JLjU"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0s7NkMOJcLv",
        "outputId": "a23e0705-e3fd-4a25-c63f-73c37623d9bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './drive/MyDrive/'\n",
        "train_lang = 'en'"
      ],
      "metadata": {
        "id": "5UkObs2AKGgC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class DatasetSeq(Dataset):\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\t#open file\n",
        "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
        "            train = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        train = [x for x in train if not '_ ' in x]\n",
        "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
        "        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n",
        "        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
        "        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
        "\t    \n",
        "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
        "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
        "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
        "\n",
        "\t    #init encoded sequences lists (processed data)\n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        # n=1 because first value is padding\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "        for line in train:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], #  (1)\n",
        "        }"
      ],
      "metadata": {
        "id": "QqtmHin0Ks9d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.listdir('drive/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuXKZAGOLp0t",
        "outputId": "b51e5dd4-2cb8-4172-db54-3c79b9a7393b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab Notebooks', 'en.train']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq(data_dir)"
      ],
      "metadata": {
        "id": "aTs5Bb05K0db"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ],
      "metadata": {
        "id": "PfC8U2JBMmk1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM predictor\n",
        "\n",
        "class LSTMPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True )\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.lstm(emb)\n",
        "\n",
        "        classes = self.classifier(hidden)\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "32EgnunKMxNv"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN predictor\n",
        "\n",
        "class RNNPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        classes = self.classifier(hidden)\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "tU_rqjF7Mzp_"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU predictor\n",
        "\n",
        "class GRUPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.gru = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(hidden_dim, n_classes)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.gru(emb)\n",
        "\n",
        "        classes = self.classifier(hidden)\n",
        "\n",
        "        return classes"
      ],
      "metadata": {
        "id": "PdtA-h84M24C"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "vocab_size = len(dataset.word_vocab) + 1\n",
        "n_classes = len(dataset.target_vocab) + 1\n",
        "n_chars = len(dataset.char_vocab) + 1\n",
        "#TODO try to use other model parameters\n",
        "emb_dim = 64\n",
        "hidden = 128\n",
        "n_epochs = 1\n",
        "cuda_device = -1\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "b7AOdj-mNMYv"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "c4Wkxj2tQa-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = LSTMPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "lstm_model.train()\n",
        "lstm_optim = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "lstm_loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "e-TMMwe-Pavy"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    start = datetime.datetime.now()\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        lstm_optim.zero_grad()\n",
        "        predict = lstm_model(batch['data'].to(device))\n",
        "        loss = lstm_loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1))\n",
        "        loss.backward()\n",
        "        lstm_optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    lstm_end = datetime.datetime.now() - start\n",
        "   \n",
        "    torch.save(lstm_model.state_dict(), f'./rnn_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNMYIbHNQZtT",
        "outputId": "197b1c7f-691d-4533-f1ca-14ff5b62be67"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.931715965270996\n",
            "epoch: 0, step: 100, loss: 0.38616907596588135\n",
            "epoch: 0, step: 200, loss: 0.2701267600059509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "EjnRsg1kQd5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = RNNPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "rnn_model.train()\n",
        "rnn_optim = torch.optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "rnn_loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "XV2usyX_Pemk"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    start = datetime.datetime.now()\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        rnn_optim.zero_grad()\n",
        "        predict = rnn_model(batch['data'].to(device))\n",
        "        loss = rnn_loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1))\n",
        "        loss.backward()\n",
        "        rnn_optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    rnn_end = datetime.datetime.now() - start\n",
        "   \n",
        "    torch.save(rnn_model.state_dict(), f'./rnn_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKRcl_3lRYzL",
        "outputId": "b02f9458-9b2b-4899-9814-7ac187f47527"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.892315626144409\n",
            "epoch: 0, step: 100, loss: 0.30005085468292236\n",
            "epoch: 0, step: 200, loss: 0.10036728531122208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU"
      ],
      "metadata": {
        "id": "Ky8E3pN0QgYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = GRUPredictor(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "gru_model.train()\n",
        "gru_optim = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "gru_loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "MAvN_za9Pe2s"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    start = datetime.datetime.now()\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        gru_optim.zero_grad()\n",
        "\n",
        "        predict = gru_model(batch['data'].to(device))\n",
        "        loss = gru_loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        gru_optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    gru_end = datetime.datetime.now() - start\n",
        "   \n",
        "    torch.save(gru_model.state_dict(), f'./rnn_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro7yPRNLo__X",
        "outputId": "a00c94d7-cd15-4fcf-8692-d5ca73e393c9"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.9341320991516113\n",
            "epoch: 0, step: 100, loss: 0.27032533288002014\n",
            "epoch: 0, step: 200, loss: 0.16760151088237762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample"
      ],
      "metadata": {
        "id": "FwL0LHdGr4iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./drive/MyDrive/en.train') as f:\n",
        "  file = f.readlines()"
      ],
      "metadata": {
        "id": "sex854y-GxQX"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = []\n",
        "for el in phrase.split(' '):\n",
        "  for line in file:\n",
        "    next = line.split(' ')\n",
        "    if el == next[0] :\n",
        "      targets.append(next[1].strip())\n",
        "      break"
      ],
      "metadata": {
        "id": "eF-WtYpZDZ7v"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(predict, targets):\n",
        "  correct = 0\n",
        "  all = 0\n",
        "  for i in range(len(predict)):\n",
        "    all += 1\n",
        "    if predict[i] == targets[i]:\n",
        "      correct += 1\n",
        "\n",
        "  return correct/all\n",
        "    "
      ],
      "metadata": {
        "id": "1oMKNHcDHe98"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'More over you can also find 10 lines on the selected far topic in English for the speeches in school programs These Ten lines in English will assist students and teachers at the time of school speeches on special events Hence students can refer to the below provided massive list of essays in English and participate in any kind of events conducted by school'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    lstm_model.eval()\n",
        "    predict = lstm_model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    lstm_iend = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "lstm_targets = [target_labels[l-1] for l in labels]\n",
        "print(acc(lstm_targets,targets))\n",
        "print(f'lstm speed: {lstm_iend}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2_8R2UWq53n",
        "outputId": "b8ac1edc-9a7d-4c27-eeed-5c2c5218dad1"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n",
            "lstm speed: 0:00:00.012415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example rnn\n",
        "phrase = 'More over you can also find 10 lines on the selected far topic in English for the speeches in school programs These Ten lines in English will assist students and teachers at the time of school speeches on special events Hence students can refer to the below provided massive list of essays in English and participate in any kind of events conducted by school'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    rnn_model.eval()\n",
        "    predict = rnn_model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    rnn_iend = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "rnn_targets = [target_labels[l-1] for l in labels]\n",
        "print(acc(rnn_targets,targets))\n",
        "print(f'rnn inference: {rnn_iend}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Am5qn0u6Zx",
        "outputId": "e43f82f6-100f-4304-b063-9f6f83e3985b"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n",
            "rnn inference: 0:00:00.003450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example gru\n",
        "phrase = 'More over you can also find 10 lines on the selected far topic in English for the speeches in school programs These Ten lines in English will assist students and teachers at the time of school speeches on special events Hence students can refer to the below provided massive list of essays in English and participate in any kind of events conducted by school'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    gru_model.eval()\n",
        "    predict = gru_model(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    gru_iend = datetime.datetime.now() - start\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "gru_targets = [target_labels[l-1] for l in labels]\n",
        "print(acc(gru_targets,targets))\n",
        "print(f'gru inference: {gru_iend}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPW9h5UCvBlE",
        "outputId": "ac868999-26e8-4665-83d0-e987e22a59aa"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.828125\n",
            "gru inference: 0:00:00.010734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'lstm training for 1 epoch: {lstm_end}')\n",
        "print(f'rnn training for 1 epoch: {rnn_end}')\n",
        "print(f'gru training for 1 epoch: {gru_end}')\n",
        "\n",
        "print(f'lstm inference: {lstm_iend}')\n",
        "print(f'rnn inference: {rnn_iend}')\n",
        "print(f'gru inference: {gru_iend}')\n",
        "\n",
        "print(f'lstm acc: {acc(lstm_targets,targets)}')\n",
        "print(f'rnn acc: {acc(rnn_targets,targets)}')\n",
        "print(f'gru acc: {acc(gru_targets,targets)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBY-EDZN4ZKY",
        "outputId": "0a35228a-c656-4c54-9c06-dd44c641e6a3"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm training for 1 epoch: 0:04:10.413886\n",
            "rnn training for 1 epoch: 0:01:13.282854\n",
            "gru training for 1 epoch: 0:03:16.439727\n",
            "lstm inference: 0:00:00.012415\n",
            "rnn inference: 0:00:00.003450\n",
            "gru inference: 0:00:00.010734\n",
            "lstm acc: 0.75\n",
            "rnn acc: 0.75\n",
            "gru acc: 0.828125\n"
          ]
        }
      ]
    }
  ]
}